{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "calculating_cosines_gensim_models.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andrewpkitchin/speciesism-in-everyday-language/blob/main/calculating_cosines_gensim_models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cJTMIpWzZjMN"
      },
      "source": [
        "In this Python 3 notebook, we will demonstrate how to use word embedding models supported by the Gensim library to generate the results used in [link to paper]. We will calculate the cosine between each focal enitity and each moral concern word.\n",
        "\n",
        "See https://github.com/RaRe-Technologies/gensim-data for a list of models and documentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZDx2Cx4Zd97"
      },
      "source": [
        "# Dependancies\n",
        "\n",
        "import csv, numpy as np, gensim.downloader as api"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh4VuYvwZibg"
      },
      "source": [
        "# List of contempary models we have used. Information on these can be found at https://github.com/RaRe-Technologies/gensim-data\n",
        "\n",
        "list_of_models = ['word2vec-google-news-300']\n",
        "\n",
        "#Google News Model\n",
        "  #'word2vec-google-news-300'\n",
        "#Twitter Models\n",
        "  #'glove-twitter-100', 'glove-twitter-200', 'glove-twitter-25', 'glove-twitter-50', \n",
        "#Wikipedia Models\n",
        "  #'glove-wiki-gigaword-100', 'glove-wiki-gigaword-200', 'glove-wiki-gigaword-300', 'glove-wiki-gigaword-50',\n",
        "  #'fasttext-wiki-news-subwords-300'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqHQbFFXZoy-"
      },
      "source": [
        "Here we create a function which returns the normalized vector representation of a word from a model. Note: word_vector will be defined as follows:\n",
        "\n",
        "word_vector = api.load(model_name)\n",
        "\n",
        "we will define this when we load and run the models. We also create a function to compute the cosine similarity of each pair of words from two input lists."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "glnLC2KHZsox"
      },
      "source": [
        "def norm(word):\n",
        "  return word_vector[word]/np.linalg.norm(word_vector[word])\n",
        " \n",
        "def cosine_similarity(vec1,vec2):\n",
        "  return np.dot(vec1, vec2)/(np.linalg.norm(vec1)* np.linalg.norm(vec2))\n",
        "\n",
        "def average_vector(list_of_words, average_vec):\n",
        "  for word in list_of_words:\n",
        "    try:\n",
        "      average_vec += norm(word)\n",
        "    except KeyError:\n",
        "      continue\n",
        "  \n",
        "  return average_vec/(len(list_of_words)+1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXdbH1z8ZvOV"
      },
      "source": [
        "def cosines_to_csv(csv_name, list1, list2, model_name):\n",
        "  with open(csv_name, 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "\n",
        "    list2.insert(0,model_name)\n",
        "\n",
        "    # Write the headings to the csv.\n",
        "    writer.writerow(list2)\n",
        "\n",
        "    list2.pop(0)\n",
        "\n",
        "    for word in list1:\n",
        "      listOfCosines = []\n",
        "      listOfCosines.append(word)\n",
        "      \n",
        "      for entity in list2:\n",
        "        try:\n",
        "          listOfCosines.append(cosine_similarity(norm(word),norm(entity)))\n",
        "        except KeyError:\n",
        "          listOfCosines.append('NA')\n",
        "\n",
        "      # Writing the cosine scores to the csv.\n",
        "      writer.writerow(listOfCosines)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvm6GAl7ZyBU"
      },
      "source": [
        "humans_and_animals = ['human', 'humans', 'person', 'persons', 'peoples', 'people', 'adult', 'adults', 'teenager', 'teenagers', 'child', 'children', 'kid', 'kids', 'man', 'men', 'woman', 'women', 'lady', 'ladies', 'gentleman', 'gentlemen', 'boy', 'boys', 'girl', 'girls', 'guy', 'gal', 'baby', 'babies', 'infant', 'infants', 'toddler', 'toddlers', 'newborn', 'newborns', 'cat', 'cats', 'kitten', 'kittens', 'dog', 'dogs', 'puppy', 'puppies', 'horse', 'horses', 'dolphin', 'dolphins', 'chimp', 'chimps', 'bear', 'bears', 'kangaroo', 'kangaroo', 'chicken', 'chickens', 'chick', 'chicks', 'goat', 'goats', 'sheep', 'lamb', 'lambs', 'pig', 'pigs', 'turkey', 'turkeys', 'cow', 'cows', 'calf', 'calves', 'duck', 'ducks', 'snake', 'snakes', 'snail', 'snails', 'starfish', 'crocodile', 'crocodiles', 'bat', 'bats', 'frog', 'frogs']\n",
        "attributes = ['care', 'cares', 'caring', 'cared', 'concern', 'concerns', 'concerned', 'concerning', 'sympathy', 'sympathize', 'sympathetic', 'compassion', 'compassionate', 'apathy', 'uncaring', 'unconcerned', 'indifference', 'indifferent', 'disregard', 'disregarded', 'disregarding', 'value', 'valuable', 'valued', 'invaluable', 'important', 'importance', 'worth', 'precious', 'cherish', 'cherished', 'significant', 'valueless', 'worthless', 'insignificant', 'meritless', 'unimportant', 'unimportance', 'deficient', 'lacking', 'disfavored', 'useless'] "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oT6WiSY0Z6c8"
      },
      "source": [
        "\n",
        "Computing the cosine similarity between each entity word and each attribute."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKzTgy9FZ2-D"
      },
      "source": [
        "for i in list_of_models:\n",
        "  word_vector = api.load(i)\n",
        "  cosines_to_csv('entities_and_moral_concern_cosines_{}.csv'.format(i), attributes, humans_and_animals, i)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}